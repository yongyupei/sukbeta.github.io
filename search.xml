<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>kafka修改分区和副本数</title>
      <link href="/2018/06/19/kafka%E4%BF%AE%E6%94%B9%E5%88%86%E5%8C%BA%E5%92%8C%E5%89%AF%E6%9C%AC%E6%95%B0/"/>
      <url>/2018/06/19/kafka%E4%BF%AE%E6%94%B9%E5%88%86%E5%8C%BA%E5%92%8C%E5%89%AF%E6%9C%AC%E6%95%B0/</url>
      <content type="html"><![CDATA[<p>##kafka修改分区和副本数 </p><p>查看现在副本分配情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">../bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --describe  --topic test1</span><br><span class="line"></span><br><span class="line">Topic:test1       PartitionCount:3        ReplicationFactor:2     Configs:</span><br><span class="line">        Topic: test1      Partition: 0    Leader: 2       Replicas: 2,4   Isr: 2,4</span><br><span class="line">        Topic: test1      Partition: 1    Leader: 3       Replicas: 3,5   Isr: 3,5</span><br><span class="line">        Topic: test1      Partition: 2    Leader: 4       Replicas: 4,1   Isr: 4,1</span><br></pre></td></tr></table></figure><h3 id="topic-分区扩容"><a href="#topic-分区扩容" class="headerlink" title="topic 分区扩容"></a>topic 分区扩容</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --zookeeper 127.0.0.1:2181 -alter --partitions 4 --topic test1</span><br></pre></td></tr></table></figure><h3 id="修改备份数量"><a href="#修改备份数量" class="headerlink" title="修改备份数量"></a>修改备份数量</h3><h4 id="这个文件自己创建-格式按照下面的格式就可以了"><a href="#这个文件自己创建-格式按照下面的格式就可以了" class="headerlink" title="这个文件自己创建 格式按照下面的格式就可以了"></a>这个文件自己创建 格式按照下面的格式就可以了</h4><p>根据topic的分区情况自行修改 partitions-topic.json 文件配置  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">        &quot;partitions&quot;:</span><br><span class="line">                [</span><br><span class="line">                &#123;</span><br><span class="line">                        &quot;topic&quot;: &quot;test1&quot;,</span><br><span class="line">                        &quot;partition&quot;: 0,</span><br><span class="line">                        &quot;replicas&quot;: [8,9]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                        &quot;topic&quot;: &quot;test1&quot;,</span><br><span class="line">                        &quot;partition&quot;: 1,</span><br><span class="line">                        &quot;replicas&quot;: [0,8]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                        &quot;topic&quot;: &quot;test1&quot;,</span><br><span class="line">                        &quot;partition&quot;: 2,</span><br><span class="line">                        &quot;replicas&quot;: [8,9]</span><br><span class="line">                &#125;</span><br><span class="line">                ],</span><br><span class="line">        &quot;version&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="执行副本搬迁"><a href="#执行副本搬迁" class="headerlink" title="执行副本搬迁"></a>执行副本搬迁</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">../bin/kafka-reassign-partitions.sh --zookeeper 127.0.0.1:2181 --reassignment-json-file partitions-topic.json --execute</span><br></pre></td></tr></table></figure><h4 id="查看迁移情况："><a href="#查看迁移情况：" class="headerlink" title="查看迁移情况："></a>查看迁移情况：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">../bin/kafka-reassign-partitions.sh --zookeeper 127.0.0.1:2181 --reassignment-json-file partitions-topic.json --verify</span><br><span class="line"></span><br><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition [mx_prd_nginx_access,0] is still in progress</span><br><span class="line">Reassignment of partition [mx_prd_nginx_access,1] completed successfully</span><br><span class="line">Reassignment of partition [mx_prd_nginx_access,2] is still in progress</span><br></pre></td></tr></table></figure><h4 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h4><p>kafka-reassign-partitions.sh工具来重新分布分区。该工具有三种使用模式：  </p><ol><li>generate模式，给定需要重新分配的Topic，自动生成reassign plan（并不执行）</li><li>execute模式，根据指定的reassign plan重新分配Partition</li><li>verify模式，验证重新分配Partition是否成功</li></ol>]]></content>
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker搭建macvlan网络</title>
      <link href="/2018/06/14/docker%E6%90%AD%E5%BB%BAmacvlan%E7%BD%91%E7%BB%9C/"/>
      <url>/2018/06/14/docker%E6%90%AD%E5%BB%BAmacvlan%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<h2 id="docker-搭建macvlan-网络"><a href="#docker-搭建macvlan-网络" class="headerlink" title="docker 搭建macvlan 网络"></a>docker 搭建macvlan 网络</h2><p>  简单说，macvlan就是在宿主的网卡设置多个vlan信息，根据走的网卡不同，并带有不行的vlan标记。  </p><h3 id="交换机需要支持"><a href="#交换机需要支持" class="headerlink" title="交换机需要支持"></a>交换机需要支持</h3><p>macvlan需要交换机上有几个设置：  </p><ul><li>连接宿主的交换机接口需要改为 Trunk 模式。（这样才能多vlan通过这个口通讯）</li><li>交换机上添加macvlan设置的相应vlan信息。</li><li>三层交换机上设置各个vlan的网关地址。并实现vlan间互联。</li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>环境介绍  </p><table><thead><tr><th>宿主机IP</th><th>宿主机vlan</th><th>macvlan IP</th><th>vlan 号</th></tr></thead><tbody><tr><td>192.168.53.11</td><td>233</td><td>172.20.30.x</td><td>30</td></tr><tr><td>192.168.53.12</td><td>233</td><td>172.20.19.x</td><td>19</td></tr></tbody></table><h4 id="实时生效安装"><a href="#实时生效安装" class="headerlink" title="实时生效安装"></a>实时生效安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release</span><br><span class="line">yum install -y vconfig</span><br><span class="line">加载模块哦</span><br><span class="line">modprobe 8021q</span><br><span class="line">lsmod |grep -i 8021q</span><br><span class="line">网卡开启混合模式</span><br><span class="line">ip link set em1 promisc on</span><br><span class="line">使用vconfig命令配置vlan </span><br><span class="line">vconfig add em1 233 </span><br><span class="line">vconfig add em1 30   # 另外一台设置  vconfig add em1 19</span><br><span class="line">在em1接口上配置两个VLAN </span><br><span class="line">vconfig set_flag em1.233 1 1 </span><br><span class="line">vconfig set_flag em1.30 1 1   # 另外一台 vconfig set_flag em1.19 1 1</span><br><span class="line"></span><br><span class="line">ifconfig em1 0.0.0.0 </span><br><span class="line">ifconfig em1.233 192.168.53.11 netmask 255.255.255.0 up </span><br><span class="line">ifconfig em1.30 172.20.30.2 netmask 255.255.255.0 up</span><br></pre></td></tr></table></figure><p>这样一个临时配置就可以了， 配置docker的网络就可以，docker配置网络的命令后面一起发吧，  </p><p>上面属于临时配置，机器重启配置就没有了，不适合生产。</p><h4 id="永久配置"><a href="#永久配置" class="headerlink" title="永久配置"></a>永久配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">um install -y epel-release</span><br><span class="line">yum install -y vconfig</span><br></pre></td></tr></table></figure><p>添加模块<br>vim /etc/rc.d/rc.local 添加  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sbin/modprobe 8021q</span><br></pre></td></tr></table></figure><p>网卡开启混合模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;PROMISC=yes&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-em1</span><br></pre></td></tr></table></figure><p>修改王凯配置文件<br>vim /etc/sysconfig/network-scripts/ifcfg-em1</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=em1</span><br><span class="line">NAME=em1</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">BONDING_MASTER=yes</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=none</span><br><span class="line">PEERDNS=yes</span><br><span class="line">PROMISC=yes</span><br></pre></td></tr></table></figure><p>生成 macvlan 网卡</p><p>vim /etc/sysconfig/network-scripts/ifcfg-em1.233</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=em1.233</span><br><span class="line">NAME=em1.233</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=192.168.53.11</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.53.1</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">VLAN=yes</span><br><span class="line">NM_CONTROLLED=no</span><br></pre></td></tr></table></figure><p>vim /etc/sysconfig/network-scripts/ifcfg-em1.30</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=em1.30</span><br><span class="line">NAME=em1.30</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">VLAN=yes</span><br><span class="line">NM_CONTROLLED=no</span><br></pre></td></tr></table></figure><p>另外一台 其他配置都一样， ifcfg-em1.30 网卡信息修改为 ifcfg-em1.19 即可。  </p><p>之后重启网卡，如果配置没有问题，网络是可以连接的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/network restart</span><br></pre></td></tr></table></figure><p>以后新添加vlan的时候，也可以先做好配置文件。直接ifup即可。<br>ifup /etc/sysconfig/network-scripts/ifcfg-em1.19</p><p>网络信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[root@wd-slave01 ~]# ifconfig</span><br><span class="line">em1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet6 fe80::d6be:d9ff:feae:80cf  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether d4:be:d9:ae:80:cf  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 108408  bytes 17234693 (16.4 MiB)</span><br><span class="line">        RX errors 0  dropped 11508  overruns 0  frame 0</span><br><span class="line">        TX packets 24225  bytes 4849942 (4.6 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">        </span><br><span class="line">docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.17.0.1  netmask 255.255.0.0  broadcast 0.0.0.0</span><br><span class="line">        inet6 fe80::42:87ff:fecd:c222  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 02:42:87:cd:c2:22  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 458940  bytes 71009715 (67.7 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 198525  bytes 55224280 (52.6 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">em1.233: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.53.12  netmask 255.255.255.0  broadcast 192.168.53.255</span><br><span class="line">        inet6 fe80::d6be:d9ff:feae:80cf  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether d4:be:d9:ae:80:cf  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 108408  bytes 17234693 (16.4 MiB)</span><br><span class="line">        RX errors 0  dropped 11508  overruns 0  frame 0</span><br><span class="line">        TX packets 24225  bytes 4849942 (4.6 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">em1.30: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet6 fe80::d6be:d9ff:feae:80cf  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether d4:be:d9:ae:80:cf  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 2133458  bytes 245138875 (233.7 MiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 1343034  bytes 151915911 (144.8 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><h4 id="docker-配置网络"><a href="#docker-配置网络" class="headerlink" title="docker 配置网络"></a>docker 配置网络</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create -d macvlan --subnet=172.20.30.0 --gateway=172.20.30.1 -o parent=em1.30 mac_net1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker network ls   查看网络情况    </span><br><span class="line">docker network inspect 074ebc238447  查看网络详细信息及ip地址分配清凉</span><br></pre></td></tr></table></figure><p>启动容器   指定IP 指定网络  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name test1 --ip=172.55.55.10 --network mac_net1 nginx-nettools:1.13  </span><br><span class="line">或动态分配</span><br><span class="line">docker run -d --name test2  --network mac_net1 nginx-nettools:1.13</span><br></pre></td></tr></table></figure><p>限制分配ip地址池</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker network create -d macvlan --subnet=172.20.30.0/24 --gateway=172.20.30.1 --ip-range=172.20.30.48/30 -o parent=em1.20 mac_net30</span><br><span class="line">这样只能分配4个ip地址</span><br><span class="line">172.20.30.128/25 也就是 128-255 可得 128个ip地址</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> macvlan </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux 删除乱码文件</title>
      <link href="/2018/06/04/linux-%E5%88%A0%E9%99%A4%E4%B9%B1%E7%A0%81%E6%96%87%E4%BB%B6/"/>
      <url>/2018/06/04/linux-%E5%88%A0%E9%99%A4%E4%B9%B1%E7%A0%81%E6%96%87%E4%BB%B6/</url>
      <content type="html"><![CDATA[<h2 id="linux-利用-inum-删除乱码文件"><a href="#linux-利用-inum-删除乱码文件" class="headerlink" title="linux 利用 inum 删除乱码文件"></a>linux 利用 inum 删除乱码文件</h2><p>  当系统中产生一些乱码文件的时候，rm直接是删除不掉的。如 “-，&amp;”等一些特殊字符。<br>  这时候我们可以利用linux 的inum 号来找到这个文件，并删除。</p><p>  例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@test00 ~]# ll -i</span><br><span class="line">总用量 4</span><br><span class="line">   213388 -rw-r--r--. 1 root root    0 6月   4 07:40 -c</span><br><span class="line">134938544 drwxr-xr-x. 2 root root   23 12月 18 05:12 123</span><br><span class="line">   213391 -rw-r--r--. 1 root root    0 6月   4 07:40 --poolmetadata</span><br><span class="line">   213390 -rw-r--r--. 1 root root    0 6月   4 07:40 --thinpool</span><br><span class="line">   213387 -rw-r--r--. 1 root root    0 6月   4 07:40 --zero</span><br></pre></td></tr></table></figure><p>利用inum 号删除文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">删除文件或文件夹</span><br><span class="line">find ./ -inum 213388 -print -exec rm &#123;&#125; -rf \;</span><br><span class="line">删除文件</span><br><span class="line">find ./ -inum 213388 -delete;</span><br></pre></td></tr></table></figure><p>也可以重命名乱码文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find ./ -inum 213388 -exec mv &#123;&#125; newfile \;</span><br></pre></td></tr></table></figure><p>文件名字就改为了 newfile</p>]]></content>
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> rm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>logstash out file to HDFS</title>
      <link href="/2018/05/29/logstash-out-file-to-HDFS/"/>
      <url>/2018/05/29/logstash-out-file-to-HDFS/</url>
      <content type="html"><![CDATA[<h2 id="logstash-out-file-to-HDFS"><a href="#logstash-out-file-to-HDFS" class="headerlink" title="logstash out file to HDFS"></a>logstash out file to HDFS</h2><p>  logstash 直接把文件内容写入 hdfs 中， 并支持 hdfs 压缩格式。<br>  logstash 需要安装第三方插件，webhdfs插件，通过hdfs的web接口写入。<br>  即 <a href="http://namenode00:50070/webhdfs/v1/" target="_blank" rel="noopener">http://namenode00:50070/webhdfs/v1/</a>  接口  </p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>  可以在官网找到相应的版本， 我们用的是2.3.1，下载地址：  </p><pre><code>https://www.elastic.co/downloads/past-releases  </code></pre><p>  webhdfs插件地址  </p><pre><code>github地址：  git clone  https://github.com/heqin5136/logstash-output-webhdfs-discontinued.git官网地址及使用说明：  https://www.elastic.co/guide/en/logstash/current/plugins-outputs-webhdfs.html</code></pre><p>插件安装方式：</p><pre><code>logstash 安装在 /home/mtime/logstash-2.3.1git clone  https://github.com/heqin5136/logstash-output-webhdfs-discontinued.gitcd logstash-output-webhdfs-discontinued/home/mtime/logstash-2.3.1/bin/plugin install logstash-output-webhdfs-discontinued</code></pre><p>检查hdfs的webhds接口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">   curl -i  &quot;http://namenode:50070/webhdfs/v1/?user.name=hadoop&amp;op=LISTSTATUS&quot;   </span><br><span class="line">   </span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Cache-Control: no-cache</span><br><span class="line">Expires: Thu, 13 Jul 2017 04:53:39 GMT</span><br><span class="line">Date: Thu, 13 Jul 2017 04:53:39 GMT</span><br><span class="line">Pragma: no-cache</span><br><span class="line">Expires: Thu, 13 Jul 2017 04:53:39 GMT</span><br><span class="line">Date: Thu, 13 Jul 2017 04:53:39 GMT</span><br><span class="line">Pragma: no-cache</span><br><span class="line">Content-Type: application/json</span><br><span class="line">Set-Cookie: hadoop.auth=&quot;u=hadoop&amp;p=hadoop&amp;t=simple&amp;e=1499957619679&amp;s=KSxdSAtjXAllhn73vh1MAurG9Bk=&quot;; Path=/; Expires=Thu, 13-Jul-2017 14:53:39 GMT; HttpOnly</span><br><span class="line">Transfer-Encoding: chunked</span><br><span class="line">Server: Jetty(6.1.26)</span><br></pre></td></tr></table></figure><p>注释： active namenode 返回是200 ，standby namenode 返回是403.</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>添加 logstash 一个配置文件</p><p>vim /home/mtime/logstash-2.3.1/conf/hdfs.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    zk_connect =&gt; &quot;192.168.51.191:2181,192.168.51.192:2181,192.168.51.193:2181&quot;   ## kafka zk 地址 </span><br><span class="line">    group_id =&gt; &apos;hdfs&apos;   # 消费者组</span><br><span class="line">    topic_id =&gt; &apos;tracks&apos;  # topic 名字</span><br><span class="line">    consumer_threads =&gt; 1  </span><br><span class="line">    codec =&gt; &apos;json&apos;  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;   ##  为解决 插入hdfs时间相差8小时， </span><br><span class="line">        date &#123;  </span><br><span class="line">                match =&gt; [ &quot;time&quot; , &quot;yyyy-MM-dd HH:mm:ss&quot; ]</span><br><span class="line">                locale =&gt; &quot;zh&quot;</span><br><span class="line">                timezone =&gt; &quot;-00:00:00&quot;</span><br><span class="line">                target =&gt; &quot;@timestamp&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">#if [app] == &quot;mx.tc.virtualcard.service&quot; &#123;</span><br><span class="line">    webhdfs &#123;</span><br><span class="line">           workers =&gt; 2</span><br><span class="line">           host =&gt; &quot;192.168.53.101&quot;</span><br><span class="line">           standby_host =&gt; &quot;192.168.53.100&quot;</span><br><span class="line">           port =&gt; 50070</span><br><span class="line">           user =&gt; &quot;loguser&quot;</span><br><span class="line">           path =&gt; &quot;/Service-Data/%&#123;+YYYY&#125;-%&#123;+MM&#125;-%&#123;+dd&#125;/%&#123;app&#125;/logstash-%&#123;+HH&#125;.log&quot;</span><br><span class="line">           flush_size =&gt; 100</span><br><span class="line">           idle_flush_time =&gt; 10</span><br><span class="line">           compression =&gt; &quot;gzip&quot;</span><br><span class="line">           retry_interval =&gt; 3</span><br><span class="line">           codec =&gt; &apos;json&apos;   # 解决 写入hdfs文件是json格式，否则内容为 %&#123;message&#125;</span><br><span class="line">       &#125;</span><br><span class="line">#   &#125;</span><br><span class="line">  stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于hdfs部分配置，可以在 <a href="https://www.elastic.co/guide/en/logstash/current/plugins-outputs-webhdfs.html" target="_blank" rel="noopener">plugins-outputs-webhdfs</a>  官网找到。</p><h3 id="启动-logstart"><a href="#启动-logstart" class="headerlink" title="启动 logstart"></a>启动 logstart</h3><pre><code>cd /home/mtime/logstash-2.3.1/bin/./logstash -f ../conf/hdfs.conf    # 为前台启动 </code></pre>]]></content>
      
      <categories>
          
          <category> logstash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logstash </tag>
            
            <tag> hdfs </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mesos容器映射端口限制</title>
      <link href="/2018/05/29/mesos%E5%AE%B9%E5%99%A8%E6%98%A0%E5%B0%84%E7%AB%AF%E5%8F%A3%E9%99%90%E5%88%B6/"/>
      <url>/2018/05/29/mesos%E5%AE%B9%E5%99%A8%E6%98%A0%E5%B0%84%E7%AB%AF%E5%8F%A3%E9%99%90%E5%88%B6/</url>
      <content type="html"><![CDATA[<h2 id="mesos-容器映射端口限制"><a href="#mesos-容器映射端口限制" class="headerlink" title="mesos 容器映射端口限制"></a>mesos 容器映射端口限制</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>  mesos 在启动容器的时候，理念是容器内的端都映射到宿主的随机端口。<br>  在容器的时代，其实这样的理念是很好，当容器多的时候，固定端口肯定是有一定的局限性的。可以通过注册中心、mesos-dns、marathon-lb等服务来找到你要的服务地址和端口。<br>  但是有时候有一些服务需要一些固定端口。比如cadvisor、还有我们自己写的容器，可能会映射一些其他端口。  </p><h3 id="默认端口限制"><a href="#默认端口限制" class="headerlink" title="默认端口限制"></a>默认端口限制</h3><p>  默认mesos的端口也是可以指定的，只是范围比较小。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">31000 - 32000</span><br></pre></td></tr></table></figure><p>  marahotn 的json 文件中，你可以写。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&quot;portMappings&quot;: [</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;containerPort&quot;: 80,</span><br><span class="line">    &quot;hostPort&quot;: 31000,  # 一般设置 0 为随机端口，</span><br><span class="line">    &quot;servicePort&quot;: 0,</span><br><span class="line">    &quot;protocol&quot;: &quot;tcp&quot;</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>docker 启动时候就是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@test00 ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS                            NAMES</span><br><span class="line">70314cd31714        nginx-nettools:1.13   &quot;nginx -g &apos;daemon ...&quot;   24 minutes ago      Up 24 minutes       443/tcp, 0.0.0.0:31000-&gt;80/tcp   mesos-07a768f1-f635-4517-9b60-4e86bfef658e</span><br></pre></td></tr></table></figure><h3 id="配置mesos"><a href="#配置mesos" class="headerlink" title="配置mesos"></a>配置mesos</h3><p>yum 安装的meoss 添加配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;ports(*):[1024-65534]&quot; &gt; /etc/mesos-slave/resources</span><br></pre></td></tr></table></figure><p>重启 mesos-slave 服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart mesos-slave</span><br></pre></td></tr></table></figure><p>二进制安装的mesos 在启动命令中添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--resources=ports(*):[1024-65534]</span><br></pre></td></tr></table></figure><p>这样你的端口就是在 1024 - 65524 中间随意指定了。</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>marathon json文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&quot;portMappings&quot;: [</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;containerPort&quot;: 80,</span><br><span class="line">    &quot;hostPort&quot;: 8080,</span><br><span class="line">    &quot;servicePort&quot;: 0,</span><br><span class="line">    &quot;protocol&quot;: &quot;tcp&quot;</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>docker 启动时候是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@test00 ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS                           NAMES</span><br><span class="line">1235513ee658        nginx-nettools:1.13   &quot;nginx -g &apos;daemon ...&quot;   6 minutes ago       Up 6 minutes        443/tcp, 0.0.0.0:8080-&gt;80/tcp   mesos-655d4923-0d1f-4130-8d61-aab824df3f25-S13.9e0c2cfb-3d07-467f-ac47-08e492703263</span><br></pre></td></tr></table></figure><h3 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h3><p>如果mesos上运行过容器，在你修改配置文件之后重启会有问题。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">你可以通过</span><br><span class="line">journalctl -xe</span><br><span class="line">或</span><br><span class="line">查看mesos的log日志 找到问题</span><br></pre></td></tr></table></figure><p>解决方法： 日志中会有提示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">To remedy this do as follows:</span><br><span class="line">Step 1: rm -f /home/mtime/mesos/meta/slaves/latest</span><br><span class="line">        This ensures agent doesn&apos;t recover old live executors.</span><br><span class="line">  ep 2: Restart the agent.</span><br></pre></td></tr></table></figure><p>rm -f /home/mtime/mesos/meta/slaves/latest<br>删除之后在重启即可。</p>]]></content>
      
      <categories>
          
          <category> mesos </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mesos </tag>
            
            <tag> port </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon私有仓库用户名和密码方式</title>
      <link href="/2018/05/28/marathon%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E5%AF%86%E7%A0%81%E6%96%B9%E5%BC%8F/"/>
      <url>/2018/05/28/marathon%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E5%AF%86%E7%A0%81%E6%96%B9%E5%BC%8F/</url>
      <content type="html"><![CDATA[<h1 id="marathon-使用仓库用户名和密码方式"><a href="#marathon-使用仓库用户名和密码方式" class="headerlink" title="marathon 使用仓库用户名和密码方式"></a>marathon 使用仓库用户名和密码方式</h1><h2 id="首先需要本地手动登入镜像仓库。"><a href="#首先需要本地手动登入镜像仓库。" class="headerlink" title="首先需要本地手动登入镜像仓库。"></a>首先需要本地手动登入镜像仓库。</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># docker login registry.inc-test.com</span><br><span class="line">   Username: admin </span><br><span class="line">   Password: Default@123</span><br></pre></td></tr></table></figure><p>登入成功之后会在当前用户的家目录创建一个隐藏目录 ~/.docker ，打包这么目录，放在一个目录下， 并让marathon启动容器的时候引用这个文件即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># cd ~</span><br><span class="line"># tar czf docker.tar.gz .docker</span><br><span class="line"></span><br><span class="line"># cp docker.tar.gz /etc/</span><br></pre></td></tr></table></figure><h2 id="marathon-json-启动容器引用验证文件"><a href="#marathon-json-启动容器引用验证文件" class="headerlink" title="marathon json 启动容器引用验证文件"></a>marathon json 启动容器引用验证文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;uris&quot;: [</span><br><span class="line">   &quot;file:///etc/docker.tar.gz&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>注释：  </p><ul><li>这样需要每台mesos slave机器都需要放置这个文件，实际操作很不灵活，</li><li>而且用户切换也不好做，每台机器需要放不不用户的验证文件。</li><li>如果用户密码修改，还需要批量修改每台slave机器上的验证文件。</li></ul><h2 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h2><ul><li>把这个文件放在http页面上，只要网络通就可以访问，不需要每台机器都配置验证文件，修改也比较访问。</li></ul><p>把docker.tar.gz文件放在http页面中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp /etc/docker.tar.gz 10.10.130.201:/var/www/html/download/docker_img/harbor-admin.tar.gz</span><br><span class="line"></span><br><span class="line"># 一个用户手动生成一个文件，如需要切换用户的时候指定不同文件即可。</span><br></pre></td></tr></table></figure><h2 id="例如："><a href="#例如：" class="headerlink" title="例如："></a>例如：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;id&quot;: &quot;nginx&quot;,</span><br><span class="line">    &quot;cpus&quot;: 0.2,</span><br><span class="line">    &quot;mem&quot;: 128,</span><br><span class="line">    &quot;instances&quot;: 1,</span><br><span class="line">    &quot;constraints&quot;: [</span><br><span class="line">        [</span><br><span class="line">            &quot;hostname&quot;,</span><br><span class="line">            &quot;CLUSTER&quot;,</span><br><span class="line">            &quot;es02.host-test.com&quot;</span><br><span class="line">        ]</span><br><span class="line">    ],</span><br><span class="line">    &quot;uris&quot;: [</span><br><span class="line">        &quot;http://10.10.130.201/download/docker_img/harbor-admin.tar.gz&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;container&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;DOCKER&quot;,</span><br><span class="line">        &quot;docker&quot;: &#123;</span><br><span class="line">            &quot;image&quot;: &quot;registry.inc-test.com/web-lb/nginx:1.13&quot;,</span><br><span class="line">            &quot;network&quot;: &quot;BRIDGE&quot;,</span><br><span class="line">            &quot;portMappings&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;containerPort&quot;: 80,</span><br><span class="line">                    &quot;hostPort&quot;: 31009,</span><br><span class="line">                    &quot;servicePort&quot;: 0,</span><br><span class="line">                    &quot;protocol&quot;: &quot;tcp&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>marathon 官网说明 <a href="https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html" target="_blank" rel="noopener">https://mesosphere.github.io/marathon/docs/native-docker-private-registry.html</a></p>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mesos解决sandbox日志切分问题</title>
      <link href="/2018/05/28/mesos%E8%A7%A3%E5%86%B3sandbox%E6%97%A5%E5%BF%97%E5%88%87%E5%88%86%E9%97%AE%E9%A2%98/"/>
      <url>/2018/05/28/mesos%E8%A7%A3%E5%86%B3sandbox%E6%97%A5%E5%BF%97%E5%88%87%E5%88%86%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<h1 id="mesos-解决sandbox日志切分问题"><a href="#mesos-解决sandbox日志切分问题" class="headerlink" title="mesos 解决sandbox日志切分问题"></a>mesos 解决sandbox日志切分问题</h1><p>mesos运行的docker容器，容器打印到前台console的日志会记录到mesos的work目录中容器沙箱中stdout和stderr文件中，容器不重启，日志会一直变大，这样会到只宿主空间变大。  </p><p>另外这份日志还会日志到系统的/var/log/messages 文件中。  </p><p>首先关于 mesos-slave 的 work-dir 中设置的目录，里面存放的docker容器的沙箱目录，会有 stderr\stdout等文件，其中这两个文件是记录容器console的日志，会一直保留，直到容器销毁，这样日志文件会持续增大。</p><p>为解决这个问题问题。mesos 没有明确的配置。 <a href="http://mesos.apache.org/documentation/latest/logging/" target="_blank" rel="noopener">http://mesos.apache.org/documentation/latest/logging/</a> 文章中有提到沙箱大小的设置，但是没有测试成功。</p><p>我的解决办法：利用系统的 logrotate 模块做日志的切分和删除。</p><p>如：添加配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/logrotate.d/mesos  &lt;&lt; EOF</span><br><span class="line">/home/mtime/mesos/slaves/*/frameworks/*/executors/*/runs/latest/stderr</span><br><span class="line">/home/mtime/mesos/slaves/*/frameworks/*/executors/*/runs/latest/stdout </span><br><span class="line">&#123;</span><br><span class="line">        daily</span><br><span class="line">        missingok</span><br><span class="line">        copytruncate</span><br><span class="line">        notifempty</span><br><span class="line">        size 102400</span><br><span class="line">        dateext</span><br><span class="line">        rotate 7</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>这样每天都会切分 大于 100Mb的日志了， 并保留7天。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/usr/sbin/logrotate -d -v -f /etc/logrotate.conf</span><br><span class="line"></span><br><span class="line">-d  测试配置文件，不是真正执行。</span><br></pre></td></tr></table></figure><p>crontab  中 已经添加，logrotate 会每天执行的。/etc/cron.daily/logrotate </p>]]></content>
      
      <categories>
          
          <category> mesos </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mesos </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>marathon-lb配置及nginx负载</title>
      <link href="/2018/05/28/marathon-lb%E9%85%8D%E7%BD%AE%E5%8F%8Anginx%E8%B4%9F%E8%BD%BD/"/>
      <url>/2018/05/28/marathon-lb%E9%85%8D%E7%BD%AE%E5%8F%8Anginx%E8%B4%9F%E8%BD%BD/</url>
      <content type="html"><![CDATA[<h1 id="marathon-lb配置"><a href="#marathon-lb配置" class="headerlink" title="marathon-lb配置"></a>marathon-lb配置</h1><h2 id="marathon-lb-get-images"><a href="#marathon-lb-get-images" class="headerlink" title="marathon-lb get images"></a>marathon-lb get images</h2><p>Marathon-lb既是一个服务发现工具，也是负载均衡工具，它集成了haproxy，自动获取各个app的信息，为每一组app生成haproxy配置，通过servicePort或者web虚拟主机提供服务。</p><p>要使用marathonn-lb，每组app必须设置HAPROXY_GROUP标签。</p><p>Marathon-lb运行时绑定在各组app定义的服务端口（servicePort，如果app不定义servicePort，marathon会随机分配端口号）上，可以通过marathon-lb所在节点的相关服务端口访问各组app。</p><p>例如：marathon-lb部署在slave5，test-app 部署在slave1，test-app 的servicePort是10004，那么可以在slave5的 10004端口访问到test-app提供的服务。</p><p>由于servicePort 非80、443端口（80、443端口已被marathon-lb中的 haproxy独占），对于web服务来说不太方便，可以使用 haproxy虚拟主机解决这个问题：</p><p>在提供web服务的app配置里增加HAPROXY_{n}_VHOST（WEB虚拟主机）标签，marathon-lb会自动把这组app的WEB集群服务发布在marathon-lb所在节点的80和443端口上，用户设置DNS后通过虚拟主机名来访问。</p><h3 id="官方下载镜像"><a href="#官方下载镜像" class="headerlink" title="官方下载镜像"></a>官方下载镜像</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">images url :</span><br><span class="line">https://store.docker.com/community/images/mesosphere/marathon-lb</span><br><span class="line"></span><br><span class="line">docker pull mesosphere/marathon-lb</span><br><span class="line"></span><br><span class="line">github url:</span><br><span class="line">https://github.com/mesosphere/marathon-lb</span><br></pre></td></tr></table></figure><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>docker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --privileged -e PORTS=9090 --net=host docker.io/mesosphere/marathon-lb sse -m http://marathon1_ip:8080 -m http://marathon2_ip:8080 -m http://master3_ip:8080  --group external</span><br></pre></td></tr></table></figure><p>marathon</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">vim marathon-lb.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;id&quot;: &quot;marathon-lb-testv1&quot;,</span><br><span class="line">    &quot;instances&quot;: 1,</span><br><span class="line">    &quot;constraints&quot;: [</span><br><span class="line">        [</span><br><span class="line">            &quot;hostname&quot;,</span><br><span class="line">            &quot;CLUSTER&quot;,</span><br><span class="line">            &quot;host-hostname.com&quot;</span><br><span class="line">        ]</span><br><span class="line">    ],</span><br><span class="line">    &quot;container&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;DOCKER&quot;,</span><br><span class="line">        &quot;docker&quot;: &#123;</span><br><span class="line">            &quot;image&quot;: &quot;docker.io/mesosphere/marathon-lb:latest&quot;,</span><br><span class="line">            &quot;privileged&quot;: true,</span><br><span class="line">            &quot;network&quot;: &quot;HOST&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;args&quot;: [</span><br><span class="line">        &quot;sse&quot;,</span><br><span class="line">        &quot;-m&quot;,</span><br><span class="line">        &quot;http://10.10.131.78:8080&quot;,</span><br><span class="line">        &quot;--group&quot;,</span><br><span class="line">        &quot;external&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl -X POST http://10.10.131.78:8080/v2/apps -d @marathon-lb.json -H &quot;Content-type: application/json&quot;</span><br></pre></td></tr></table></figure><h2 id="marathon-lb-API"><a href="#marathon-lb-API" class="headerlink" title="marathon-lb API"></a>marathon-lb API</h2><table><thead><tr><th>Endpoint</th><th>Description</th></tr></thead><tbody><tr><td>:9090/haproxy?stats</td><td>HAProxy stats endpoint. This produces an HTML page which can be viewed in your browser, providing various statistics about the current HAProxy instance.</td></tr><tr><td>:9090/haproxy?stats;csv</td><td>This is a CSV version of the stats above, which can be consumed by other tools. For example, it’s used in the zdd.py script.</td></tr><tr><td>:9090/_haproxy_health_check</td><td>HAProxy health check endpoint. Returns 200 OK if HAProxy is healthy.</td></tr><tr><td>:9090/_haproxy_getconfig</td><td>Returns the HAProxy config file as it was when HAProxy was started. Implemented in getconfig.lua.</td></tr><tr><td>:9090/_haproxy_getvhostmap</td><td>Returns the HAProxy vhost to backend map. This endpoint returns HAProxy map file only when the –haproxy-map flag is enabled, it returns an empty string otherwise. Implemented in getmaps.lua.</td></tr><tr><td>:9090/_haproxy_getappmap</td><td>Returns the HAProxy app ID to backend map. Like _haproxy_getvhostmap, this requires the –haproxy-map flag to be enabled and returns an empty string otherwise. Also implemented in getmaps.lua.</td></tr><tr><td>:9090/_haproxy_getpids</td><td>Returns the PIDs for all HAProxy instances within the current process namespace. This literally returns $(pidof haproxy). Implemented in getpids.lua. This is also used by the zdd.py script to determine if connections have finished draining during a deploy.</td></tr><tr><td>:9090/_mlb_signal/hup*</td><td>Sends a SIGHUP signal to the marathon-lb process, causing it to fetch the running apps from Marathon and reload the HAProxy config as though an event was received from Marathon.</td></tr><tr><td>:9090/_mlb_signal/usr1*</td><td>Sends a SIGUSR1 signal to the marathon-lb process, causing it to restart HAProxy with the existing config, without checking Marathon for changes.</td></tr></tbody></table><ul><li>API from marathon-lb <a href="https://github.com/mesosphere/marathon-lb" target="_blank" rel="noopener">!github</a></li><li>marathon-lb 文档详解 <a href="https://github.com/mesosphere/marathon-lb/blob/master/Longhelp.md#templates" target="_blank" rel="noopener">!https://github.com/mesosphere/marathon-lb/blob/master/Longhelp.md#templates</a></li></ul><p>如常用： <a href="http://marathon-lb-ip:9090/haproxy?stats" target="_blank" rel="noopener">http://marathon-lb-ip:9090/haproxy?stats</a></p><h2 id="nginx-start"><a href="#nginx-start" class="headerlink" title="nginx start"></a>nginx start</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># vim nginx.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;id&quot;: &quot;nginx-test&quot;,</span><br><span class="line">    &quot;cpus&quot;: 0.2,</span><br><span class="line">    &quot;mem&quot;: 128,</span><br><span class="line">    &quot;instances&quot;: 1,</span><br><span class="line">  &quot;labels&quot;: &#123;</span><br><span class="line">     &quot;HAPROXY_GROUP&quot;:&quot;external&quot;</span><br><span class="line">     &quot;HAPROXY_0_VHOST&quot;:&quot;nginx.test.com&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">    &quot;uris&quot;: [</span><br><span class="line">        &quot;http://10.10.130.201/download/docker_img/db-harbor-admin.tar.gz&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;healthChecks&quot;: [&#123; &quot;path&quot;: &quot;/&quot; &#125;],</span><br><span class="line">    &quot;container&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;DOCKER&quot;,</span><br><span class="line">        &quot;docker&quot;: &#123;</span><br><span class="line">            &quot;image&quot;: &quot;nginx:1.13&quot;,</span><br><span class="line">            &quot;network&quot;: &quot;BRIDGE&quot;,</span><br><span class="line">            &quot;portMappings&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;containerPort&quot;: 80,</span><br><span class="line">                    &quot;hostPort&quot;: 0,</span><br><span class="line">                    &quot;servicePort&quot;: 10000,</span><br><span class="line">                    &quot;protocol&quot;: &quot;tcp&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># curl -X POST http://10.10.131.78:8080/v2/apps -d @nginx.json -H &quot;Content-type: application/json&quot;</span><br></pre></td></tr></table></figure><h2 id="说明："><a href="#说明：" class="headerlink" title="说明："></a>说明：</h2><ol><li>一定要加上HAPROXY_GROUP标签，它填写的是marathon-lb创建时定义的组名 </li><li>HAPROXY_0_VHOST是标签名，对于web服务可以加上VHOST标签，让marathon-lb设置WEB虚拟主机；</li><li>containerPort为80,是指容器内的端口。</li><li>hostPort是当前主机映射到contenterPort的端口，如果hostPort为0的话,则说明是随机的。</li><li>serverPort是marathon-lb需要配置的haproxy代理暴露的端口,这里设置为10000，说明访问marathon-lb机器的10000端口就可为访问这个应用容器的80端口。</li></ol><h2 id="访问marathon-lb"><a href="#访问marathon-lb" class="headerlink" title="访问marathon-lb"></a>访问marathon-lb</h2><p>ip 访问</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://marathon-lb_ip:10000/</span><br></pre></td></tr></table></figure><ul><li>访问marathon-lb部署的宿主机ip地址和serverPort的端口。</li></ul><p>域名访问</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">需要添加dns解析，根据 &quot;HAPROXY_0_VHOST&quot;:&quot;nginx.test.com&quot; 设置的配置。</span><br><span class="line">如：</span><br><span class="line">vim /etc/hosts  添加</span><br><span class="line">10.10.131.151nginx.test.com</span><br><span class="line"></span><br><span class="line">这里 10.10.131.151 是 marathon-lb 的ip地址</span><br><span class="line"></span><br><span class="line">curl nginx.test.com  即可</span><br></pre></td></tr></table></figure><h2 id="marathon-lb-代理80端口"><a href="#marathon-lb-代理80端口" class="headerlink" title="marathon-lb 代理80端口"></a>marathon-lb 代理80端口</h2><p>默认marathon-lb 80和443端口是被占用的，所以nginx在发布的时候“serverPort”是不能设置为80和443端口的。  </p><p>为了解决这个问题，需要更改源码，重新生成镜像。  </p><p>首先现在 marathon-lb源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># git clone https://github.com/mesosphere/marathon-lb.git</span><br><span class="line"># cd marathon-lb</span><br><span class="line"></span><br><span class="line">在这个目录下找到所有80、443端口信息。改为其他端口</span><br><span class="line"></span><br><span class="line"># grep 80 . -R</span><br><span class="line">找到相应文件，80 替换为7080</span><br><span class="line">:%s/80/7080/g</span><br><span class="line"></span><br><span class="line">找到相应文件，443 替换为7443</span><br><span class="line">:%s/443/7443/g</span><br></pre></td></tr></table></figure><p>重新生成镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker build -t marathon-lb-7080 .</span><br><span class="line"></span><br><span class="line">成功之后 docker images 就会多出 marathon-lb-7080 镜像</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> marathon </category>
          
      </categories>
      
      
        <tags>
            
            <tag> marathon </tag>
            
            <tag> marathon-lb </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mesos-dns搭建</title>
      <link href="/2018/05/25/mesos-dns%E6%90%AD%E5%BB%BA/"/>
      <url>/2018/05/25/mesos-dns%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<h2 id="mesos-dns-搭建"><a href="#mesos-dns-搭建" class="headerlink" title="mesos-dns 搭建"></a>mesos-dns 搭建</h2><p>  Mesos-DNS用来支持Mesos集群上的服务发现，使运行在Mesos上的应用和服务可以通过域名服务器来发现彼此。你只要知道一个Mesos数据中心上运行的应用的名字，就可以通过Mesos-DNS查询到该应用的IP和端口号。  </p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>  官方下载mesos-dns镜像没有提供mesos-dns的HTTP接口出来，所以先用二进制搭建，在自己build镜像。  </p><p>  mesos-dns文件下载：<a href="https://github.com/mesosphere/mesos-dns/releases" target="_blank" rel="noopener">!https://github.com/mesosphere/mesos-dns/releases</a></p><p>  下载 mesos-dns-v0.6.0-linux-amd64 一个二进制文件。</p><p>  准备配置文件：config.json</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;zk&quot;: &quot;zk://10.0.0.52:2181,10.0.0.53:2181,10.0.0.54:2181/mesos&quot;,</span><br><span class="line">  &quot;masters&quot;: [&quot;10.0.0.52:5050&quot;, &quot;10.0.0.53:5050&quot;, &quot;10.0.0.54:5050&quot;],</span><br><span class="line">  &quot;refreshSeconds&quot;: 10,</span><br><span class="line">  &quot;ttl&quot;: 0,</span><br><span class="line">  &quot;domain&quot;: &quot;mesos&quot;,</span><br><span class="line">  &quot;port&quot;: 53,</span><br><span class="line">  &quot;resolvers&quot;: [&quot;10.10.130.5&quot;],</span><br><span class="line">  &quot;timeout&quot;: 5, </span><br><span class="line">  &quot;httpon&quot;: true,</span><br><span class="line">  &quot;dnson&quot;: true,</span><br><span class="line">  &quot;httpport&quot;: 8123,</span><br><span class="line">  &quot;externalon&quot;: true,</span><br><span class="line">  &quot;listener&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">  &quot;SOAMname&quot;: &quot;docker-test.com&quot;,</span><br><span class="line">  &quot;SOARname&quot;: &quot;root.docker-test.com&quot;,</span><br><span class="line">  &quot;SOARefresh&quot;: 10,</span><br><span class="line">  &quot;SOARetry&quot;:   3,</span><br><span class="line">  &quot;SOAExpire&quot;:  86400,</span><br><span class="line">  &quot;SOAMinttl&quot;: 10,</span><br><span class="line">  &quot;IPSources&quot;: [&quot;netinfo&quot;, &quot;mesos&quot;, &quot;host&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动 mesos-dns</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mv mesos-dns-v0.6.0-linux-amd64 mesos-dns</span><br><span class="line">chmod +x mesos-dns</span><br><span class="line">./mesos-dns -config=config.json -v=2</span><br></pre></td></tr></table></figure><p>mesos-dns 会启动 53 和 8123 两个端口， 53 为dns端口，8123 为http api端口。  </p><h5 id="HTTP-API-接口"><a href="#HTTP-API-接口" class="headerlink" title="HTTP API 接口"></a>HTTP API 接口</h5><table><thead><tr><th>URL</th><th>说明 </th></tr></thead><tbody><tr><td> <a href="http://10.0.0.49:8123/v1/version" target="_blank" rel="noopener">http://10.0.0.49:8123/v1/version</a></td><td>mesos-dns版本信息</td></tr><tr><td> <a href="http://10.0.0.49:8123/v1/config" target="_blank" rel="noopener">http://10.0.0.49:8123/v1/config</a></td><td>mesos-dns配置信息</td></tr><tr><td> <a href="http://10.0.0.49:8123/v1/hosts/{host}" target="_blank" rel="noopener">http://10.0.0.49:8123/v1/hosts/{host}</a></td><td>该host的IP地址信息</td></tr><tr><td> <a href="http://10.0.0.49:8123/v1/services/{service}" target="_blank" rel="noopener">http://10.0.0.49:8123/v1/services/{service}</a></td><td>该service的host、IP、端口信息</td></tr></tbody></table><p> 例子：</p><pre><code>http://10.0.0.49:8123/v1/hosts/nginxqq-nginx.marathon.slave.mesos</code></pre><p>  分析：marathon.slave.mesos 是固定的，mesos是condig.json中domain定义的，在往前是从节点，marathon是框架，nginx是组，nginxqq是appid </p><pre><code>http://10.0.0.49:8123/v1/services/_nginxqq-nginx._tcp.marathon.slave.mesos  </code></pre><p>  分析： _nginxqq-nginx._tcp.marathon.slave.mesos ， nginxqq容器的ID名，nginx为组名，_tcp.marathon.slave.mesos 为固定的。</p><h5 id="dig-获取mesos-dns信息"><a href="#dig-获取mesos-dns信息" class="headerlink" title="dig 获取mesos-dns信息"></a>dig 获取mesos-dns信息</h5><p>查找app所在节点的IP</p><pre><code>dig nginxqq-nginx.marathon.slave.mesos +short</code></pre><p>查找app服务端口号</p><pre><code>dig SRV _nginxqq-nginx._tcp.marathon.slave.mesos +short </code></pre><ul><li>其中 过得到的主机名 mesos-dns 是可以解析的，就是app所在的物理机。</li></ul><h4 id="docker-images"><a href="#docker-images" class="headerlink" title="docker images"></a>docker images</h4><p>创建 docker file 目录，放入所用的文件</p><pre><code>mkdir dockerfile-mesos-dnscd dockerfile-mesos-dnscp ~/mesos-dns .cp ~/config.json .</code></pre><p>编辑 Dockerfile 文件  </p><p>vim Dockerfile</p><pre><code>FROM centos:6WORKDIR /root/ADD mesos-dns /root/ADD config.json /root/EXPOSE 53 8123CMD [&quot;/root/mesos-dns&quot;, &quot;-config=/root/config.json&quot;, &quot;-v=2&quot;]</code></pre><p>生成镜像</p><pre><code>docker build -t stg-mesos-dns:0.6.0 .</code></pre><p>运行镜像</p><pre><code>docker run  -d --name=stg-mesos-dns --net=host stg-mesos-dns:0.6.0</code></pre>]]></content>
      
      <categories>
          
          <category> mesos </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mesos </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
